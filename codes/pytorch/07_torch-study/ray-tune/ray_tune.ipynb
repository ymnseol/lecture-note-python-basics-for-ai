{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray-tune for Hyperparameter Turning\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BoostcampAITech/lecture-note-python-basics-for-ai/blob/main/codes/pytorch/07_torch-study/ray-tune/ray_tune.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3869,
     "status": "ok",
     "timestamp": 1628786556983,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "ot5y7LaCverD",
    "outputId": "25286f03-1fb2-4c49-fb9e-0f1bf186b9d0"
   },
   "outputs": [],
   "source": [
    "! pip install ray "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3265,
     "status": "ok",
     "timestamp": 1628786560246,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "hbnXPWknqV4H",
    "outputId": "ce670dac-8196-4c40-c969-da6aa1827226"
   },
   "outputs": [],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3246,
     "status": "ok",
     "timestamp": 1628786563485,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "SqfrQN2Q3nbh",
    "outputId": "cfe8ddc0-e675-4df4-90ad-b67741a2ec69"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085,
     "status": "ok",
     "timestamp": 1628786564568,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "p6v4ORGFvVaI",
    "outputId": "247a02dc-ed4c-4d7d-d86d-fd4e21a52a92"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628786564568,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "JK3lcOwElxdF"
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir=\"./data\"):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=True, download=True, transform=transform)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "    return trainset, testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628786564568,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "FAg2V_8ely9p"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, l1=120, l2=84):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, l1)\n",
    "        self.fc2 = nn.Linear(l1, l2)\n",
    "        self.fc3 = nn.Linear(l2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628786564569,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "DopzqPSkowWo"
   },
   "outputs": [],
   "source": [
    "def train_cifar(config, checkpoint_dir=None, data_dir=None):\n",
    "    net = Net(config[\"l1\"], config[\"l2\"])\n",
    "\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=0.9)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        net.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainset, testset = load_data(data_dir)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_subset,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    wandb.init(project='torch-turn', entity='teamlab')\n",
    "    wandb.watch(net)\n",
    "\n",
    "    for epoch in range(10):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        wandb.log({\"val_loss\": val_loss})\n",
    "        wandb.log({\"loss\": loss})\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1628786564569,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "BSzH6czJpX3n"
   },
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    trainset, testset = load_data()\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1246919,
     "status": "ok",
     "timestamp": 1628788687120,
     "user": {
      "displayName": "최성철/산업경영공학과",
      "photoUrl": "",
      "userId": "03123322103118209211"
     },
     "user_tz": -540
    },
    "id": "j5BkGGECo5ZS",
    "outputId": "326eb2c4-97aa-4781-b92d-efdf36139894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1,  2000] loss: 2.302\n",
      "\u001b[2m\u001b[36m(pid=1072)\u001b[0m [1,  2000] loss: 2.134\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1,  4000] loss: 1.151\n",
      "\u001b[2m\u001b[36m(pid=1072)\u001b[0m [1,  4000] loss: 0.880\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1,  6000] loss: 0.766\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1,  8000] loss: 0.574\n",
      "\u001b[2m\u001b[36m(pid=1072)\u001b[0m [1,  6000] loss: 0.543\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1, 10000] loss: 0.456\n",
      "\u001b[2m\u001b[36m(pid=1072)\u001b[0m [1,  8000] loss: 0.390\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1, 12000] loss: 0.372\n",
      "\u001b[2m\u001b[36m(pid=1072)\u001b[0m [1, 10000] loss: 0.299\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m [1, 14000] loss: 0.304\n",
      "Result for DEFAULT_66247_00000:\n",
      "  accuracy: 0.4759\n",
      "  date: 2021-08-16_03-13-19\n",
      "  done: false\n",
      "  experiment_id: 7956bade02bf442aaf2057458cbd38d1\n",
      "  hostname: 86cd04ebe720\n",
      "  iterations_since_restore: 1\n",
      "  loss: 1.434088040906191\n",
      "  node_ip: 172.17.0.2\n",
      "  pid: 1072\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 215.50442147254944\n",
      "  time_this_iter_s: 215.50442147254944\n",
      "  time_total_s: 215.50442147254944\n",
      "  timestamp: 1629083599\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: '66247_00000'\n",
      "  \n",
      "== Status ==\n",
      "Memory usage on this node: 6.3/251.8 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.434088040906191\n",
      "Resources requested: 4.0/4 CPUs, 0/2 GPUs, 0.0/2.62 GiB heap, 0.0/1.31 GiB objects (0.0/2.0 CPU_group_ebc799c57dc0ac7bbd6fa096d98bfe98, 0.0/2.0 CPU_group_dfc467d8ef73635e7c6fc05a92cecb51, 0.0/2.0 CPU_group_0_ebc799c57dc0ac7bbd6fa096d98bfe98, 0.0/2.0 CPU_group_0_dfc467d8ef73635e7c6fc05a92cecb51, 0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/work/ray_results/DEFAULT_2021-08-16_03-09-41\n",
      "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
      "+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
      "|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
      "| DEFAULT_66247_00000 | RUNNING  | 172.17.0.2:1072 |            4 |   64 |  256 | 0.00143739  | 1.43409 |     0.4759 |                    1 |\n",
      "| DEFAULT_66247_00001 | RUNNING  |                 |            2 |   32 |  128 | 0.000104786 |         |            |                      |\n",
      "| DEFAULT_66247_00002 | PENDING  |                 |            4 |    8 |   16 | 0.000726335 |         |            |                      |\n",
      "| DEFAULT_66247_00003 | PENDING  |                 |            2 |    4 |   16 | 0.00582579  |         |            |                      |\n",
      "| DEFAULT_66247_00004 | PENDING  |                 |            4 |  256 |   16 | 0.000133689 |         |            |                      |\n",
      "| DEFAULT_66247_00005 | PENDING  |                 |           16 |  256 |   64 | 0.00487797  |         |            |                      |\n",
      "| DEFAULT_66247_00006 | PENDING  |                 |            8 |    8 |  128 | 0.000154232 |         |            |                      |\n",
      "| DEFAULT_66247_00007 | PENDING  |                 |           16 |  128 |    8 | 0.000229376 |         |            |                      |\n",
      "| DEFAULT_66247_00008 | PENDING  |                 |            2 |  128 |  128 | 0.00119412  |         |            |                      |\n",
      "| DEFAULT_66247_00009 | PENDING  |                 |            8 |    8 |   64 | 0.0280826   |         |            |                      |\n",
      "+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Memory usage on this node: 6.3/251.8 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -1.434088040906191\n",
      "Resources requested: 4.0/4 CPUs, 0/2 GPUs, 0.0/2.62 GiB heap, 0.0/1.31 GiB objects (0.0/2.0 CPU_group_ebc799c57dc0ac7bbd6fa096d98bfe98, 0.0/2.0 CPU_group_dfc467d8ef73635e7c6fc05a92cecb51, 0.0/2.0 CPU_group_0_ebc799c57dc0ac7bbd6fa096d98bfe98, 0.0/2.0 CPU_group_0_dfc467d8ef73635e7c6fc05a92cecb51, 0.0/1.0 accelerator_type:GTX)\n",
      "Result logdir: /home/work/ray_results/DEFAULT_2021-08-16_03-09-41\n",
      "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
      "+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "| Trial name          | status   | loc             |   batch_size |   l1 |   l2 |          lr |    loss |   accuracy |   training_iteration |\n",
      "|---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------|\n",
      "| DEFAULT_66247_00000 | RUNNING  | 172.17.0.2:1072 |            4 |   64 |  256 | 0.00143739  | 1.43409 |     0.4759 |                    1 |\n",
      "| DEFAULT_66247_00001 | RUNNING  |                 |            2 |   32 |  128 | 0.000104786 |         |            |                      |\n",
      "| DEFAULT_66247_00002 | PENDING  |                 |            4 |    8 |   16 | 0.000726335 |         |            |                      |\n",
      "| DEFAULT_66247_00003 | PENDING  |                 |            2 |    4 |   16 | 0.00582579  |         |            |                      |\n",
      "| DEFAULT_66247_00004 | PENDING  |                 |            4 |  256 |   16 | 0.000133689 |         |            |                      |\n",
      "| DEFAULT_66247_00005 | PENDING  |                 |           16 |  256 |   64 | 0.00487797  |         |            |                      |\n",
      "| DEFAULT_66247_00006 | PENDING  |                 |            8 |    8 |  128 | 0.000154232 |         |            |                      |\n",
      "| DEFAULT_66247_00007 | PENDING  |                 |           16 |  128 |    8 | 0.000229376 |         |            |                      |\n",
      "| DEFAULT_66247_00008 | PENDING  |                 |            2 |  128 |  128 | 0.00119412  |         |            |                      |\n",
      "| DEFAULT_66247_00009 | PENDING  |                 |            8 |    8 |   64 | 0.0280826   |         |            |                      |\n",
      "+---------------------+----------+-----------------+--------------+------+------+-------------+---------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m 2021-08-16 03:13:19,829\tERROR worker.py:421 -- SystemExit was raised from the worker\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 632, in ray._raylet.task_execution_handler\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 486, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 523, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 530, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 534, in ray._raylet.execute_task\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task.function_executor\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/ray/_private/function_manager.py\", line 563, in actor_method_executor\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/ray/tune/trainable.py\", line 178, in train_buffered\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     result = self.train()\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/ray/tune/trainable.py\", line 237, in train\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     result = self.step()\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/ray/tune/function_runner.py\", line 349, in step\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     block=True, timeout=RESULT_FETCH_TIMEOUT)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/usr/lib/python3.6/queue.py\", line 173, in get\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     self.not_empty.wait(remaining)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/usr/lib/python3.6/threading.py\", line 299, in wait\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     gotit = waiter.acquire(True, timeout)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/ray/worker.py\", line 418, in sigterm_handler\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     sys.exit(1)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m   File \"/home/work/.local/lib/python3.6/site-packages/wandb/sdk/wandb_run.py\", line 131, in exit\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m     self._orig_exit(orig_code)\n",
      "\u001b[2m\u001b[36m(pid=1074)\u001b[0m SystemExit: 1\n",
      "2021-08-16 03:13:20,033\tERROR tune.py:546 -- Trials did not complete: [DEFAULT_66247_00000, DEFAULT_66247_00001, DEFAULT_66247_00002, DEFAULT_66247_00003, DEFAULT_66247_00004, DEFAULT_66247_00005, DEFAULT_66247_00006, DEFAULT_66247_00007, DEFAULT_66247_00008, DEFAULT_66247_00009]\n",
      "2021-08-16 03:13:20,035\tINFO tune.py:550 -- Total run time: 218.56 seconds (218.20 seconds for the tuning loop).\n",
      "2021-08-16 03:13:20,036\tWARNING tune.py:555 -- Experiment has been interrupted, but the most recent state was saved. You can continue running this experiment by passing `resume=True` to `tune.run()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'l1': 64, 'l2': 256, 'lr': 0.001437392863299655, 'batch_size': 4}\n",
      "Best trial final validation loss: 1.434088040906191\n",
      "Best trial final validation accuracy: 0.4759\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63eaef0729d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# You can change the number of GPUs per trial here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0a25ae829bf4e2a6cd2acfdd4e65e6a26cd9927e\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-63eaef0729d7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(num_samples, max_num_epochs, gpus_per_trial)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mbest_checkpoint_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     model_state, optimizer_state = torch.load(os.path.join(\n\u001b[0;32m---> 50\u001b[0;31m         best_checkpoint_dir, \"checkpoint\"))\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mbest_trained_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch\n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    \n",
    "    data_dir = os.path.abspath(\"./data\")\n",
    "    load_data(data_dir)\n",
    "    config = {\n",
    "        \"l1\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"l2\": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"batch_size\": tune.choice([2, 4, 8, 16])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    \n",
    "\n",
    "    result = tune.run(\n",
    "        partial(train_cifar, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = Net(best_trial.config[\"l1\"], best_trial.config[\"l2\"])\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    wandb.login(key=\"0a25ae829bf4e2a6cd2acfdd4e65e6a26cd9927e\")\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ray_tune.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Lablup FF 20.07 on Python 3.6 (CUDA 10.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
